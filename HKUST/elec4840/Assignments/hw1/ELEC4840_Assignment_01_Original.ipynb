{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApwjF_gNfBov"
      },
      "source": [
        "## ELEC4840 Assignment 1\n",
        "\n",
        "Name:\n",
        "\n",
        "Student ID:\n",
        "\n",
        "- Problem 1 (40%)\n",
        "\n",
        "- Problem 2 (60%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiRMnBEmMc26"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## HINT\n",
        "You should run training on __training dataset__, validate the model's performance during training using __validation dataset__. After finishing training, select the model that has the best performance on validation dataset, then report the model's performance based on the data of the __test dataset__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsNk1OslN67-",
        "outputId": "6f3c439b-fe12-4bf4-a0b7-dbabadc4d2cf"
      },
      "outputs": [],
      "source": [
        "# load MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=0.5,\n",
        "        std=0.5\n",
        "    )\n",
        "])\n",
        "\n",
        "data_train = datasets.MNIST(\n",
        "    root=\"./data/\",\n",
        "    transform=transform,\n",
        "    train=True,\n",
        "    download=True\n",
        ")\n",
        "\n",
        "data_test = datasets.MNIST(\n",
        "    root=\"./data/\",\n",
        "    transform=transform,\n",
        "    train=False\n",
        ")\n",
        "\n",
        "split_train_size = int(0.8*(len(data_train)))  # from test data, split 50% as validation set\n",
        "split_valid_size = len(data_train) - split_train_size  # split 50% as test set\n",
        "\n",
        "train_set, valid_set = torch.utils.data.random_split(\n",
        "    data_train, [split_train_size, split_valid_size])\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=64,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "loader_valid = torch.utils.data.DataLoader(\n",
        "    dataset=valid_set,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "loader_test = torch.utils.data.DataLoader(\n",
        "    dataset=data_test,\n",
        "    batch_size=64,\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO9I1NbYQuZr",
        "outputId": "f409c148-4124-4bbb-e7d2-f6c897fab819"
      },
      "outputs": [],
      "source": [
        "# load EMNIST dataset\n",
        "train_set = datasets.EMNIST(\n",
        "    root=\"data\",\n",
        "    split=\"balanced\",\n",
        "    download=\"True\",\n",
        "    train=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "\n",
        "test_set = datasets.EMNIST(\n",
        "    root=\"data\",\n",
        "    split=\"balanced\",\n",
        "    download=\"True\",\n",
        "    train=False,\n",
        "    transform=transform\n",
        "\n",
        ")\n",
        "entire_trainset = torch.utils.data.DataLoader(train_set, shuffle=True)\n",
        "\n",
        "split_train_size = int(0.8*(len(entire_trainset)))  # use 80% as train set\n",
        "split_valid_size = len(entire_trainset) - split_train_size  # use 20% as validation set\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(\n",
        "    train_set, [split_train_size, split_valid_size])\n",
        "\n",
        "print(f'train set size: {split_train_size}, validation set size: {split_valid_size}')\n",
        "# EMNIST loader\n",
        "loader_train_emnist = torch.utils.data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=256, # Can be modified\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "loader_val_emnist = torch.utils.data.DataLoader(\n",
        "    dataset=val_set,\n",
        "    batch_size=256, # Can be modified\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "loader_test_emnist = torch.utils.data.DataLoader(\n",
        "    dataset=test_set,\n",
        "    batch_size=256, # Can be modified\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r9vv7F8e_FK"
      },
      "source": [
        "### Problem 1. Train an MLP network on the MNIST dataset (40%)\n",
        "\n",
        "Use a four-layer MLP to train the MNIST dataset.\n",
        "\n",
        "| Layer |  Type  |       Input       |      Output       | Activation |\n",
        "| :---: | :----: | :---------------: | :---------------: | :--------: |\n",
        "|   1   | Linear |      28 * 28      |         128         |    ReLU    |\n",
        "|   2   | Linear |         128         |        64         |    ReLU    |\n",
        "|  3  | Dropout | 64 | 64 | - |\n",
        "|   4   | Linear |        64         |        32         |    ReLU    |\n",
        "|  5   | Dropout | 32 | 32 | - |\n",
        "|   6   | Linear |       32         |        10         |     -      |\n",
        "\n",
        "\n",
        "a.) Implement the function `__init__` and `forward` in the class `Model` (15%);\n",
        "\n",
        "b.) Implement the training code (15%).\n",
        "\n",
        "c.) Plot the curve of accuracy and loss(10%). Compare and discuss the results' difference between the model with / without dropout operation(5%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A8NgdpjO8Gs"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        ## ----- write your code here\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## ----- write your code here\n",
        "        ## Remember to return the output and delete the 'pass' command below\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwwrK_2spxM1"
      },
      "outputs": [],
      "source": [
        "max_epoch = 10\n",
        "use_cuda = True\n",
        "\n",
        "# model initialization\n",
        "model = Model()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "# loss function\n",
        "criterion = # -- write your code here --\n",
        "\n",
        "# optimizer\n",
        "optimizer = # -- write your code here --\n",
        "\n",
        "loss_list = []\n",
        "acc_train_list = []\n",
        "acc_valid_list = []\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    running_loss = 0.0\n",
        "    running_correct = 0\n",
        "    valid_loss = 0.0\n",
        "    valid_correct = 0\n",
        "    print(\" -- Epoch {}/{}\".format(epoch + 1, max_epoch))\n",
        "\n",
        "    # training\n",
        "    # call a function to control the dropout behaviour \n",
        "    # your code here\n",
        "\n",
        "    for data in tqdm(loader_train):\n",
        "        # set all gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # fetch data\n",
        "        images, labels = data\n",
        "        if use_cuda:\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # model forward\n",
        "        outputs = # -- write your code here --\n",
        "\n",
        "        # calculate loss\n",
        "        loss = # -- write your code here --\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        running_loss += loss.item()\n",
        "        running_correct += torch.sum(pred == labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # record loss, accuracy\n",
        "    loss = running_loss / len(train_set)\n",
        "    loss_list.append(loss)\n",
        "    acc_train = running_correct / len(train_set)\n",
        "    acc_train_list.append(acc_train.item())\n",
        "\n",
        "    # testing\n",
        "\n",
        "    # call a function to control the dropout behaviour \n",
        "    # your code here\n",
        "\n",
        "    valid_correct = 0\n",
        "    for data in loader_valid:\n",
        "        # fetch data\n",
        "        # model forward\n",
        "        # calculate loss\n",
        "\n",
        "    # Save best checkpoint\n",
        "    if # -- write your code here --:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best_checkpoint_mnist.pt')\n",
        "\n",
        "    acc_valid = valid_correct / len(valid_set)\n",
        "    acc_valid_list.append(acc_valid.item())\n",
        "    print(\"Loss {:.4f}, Train Accuracy {:.4f}%, Validation Accuracy {:.4f}%\".format(\n",
        "        loss,\n",
        "        acc_train * 100,\n",
        "        acc_valid * 100\n",
        "    ))\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load('best_checkpoint_mnist.pt'))\n",
        "\n",
        "# call a function to control the dropout behaviour \n",
        "# your code here\n",
        "\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in loader_test:\n",
        "        # fetch data\n",
        "        # model forward\n",
        "        # calculate accuracy on test set\n",
        "        pass\n",
        "acc_test=correct/total\n",
        "print(\"Best model on test set: Test Accuracy {:.4f}%\".format(\n",
        "        acc_test * 100\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo_qV1fOkdFI"
      },
      "source": [
        "c.) Plot loss and accuracy curve\n",
        "\n",
        "In the previous cell, you have recorded the loss and train/test accuracy in `loss_list`, `acc_train_list`, and `acc_test_list`, respectively. In this problem, you are required to plot two figures: 1.) training loss curve (5%); 2.) training and testing accuracy curves in the same figure (5%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ybynXZhTX32"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "## ----- write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG389yDcsk1B"
      },
      "source": [
        "### Problem 2. Train a LeNet network on the EMINIST dataset (60%)\n",
        "\n",
        "1. Implement the model and training code as instructed in the Jupyter notebook (30%);\n",
        "\n",
        "2. In the summary report, plot the loss and accuracy curve (10%);\n",
        "\n",
        "3. Try different choices of batch sizes, learning rates, or optimizers in your experiments. In the summary report, report the accuracy of your three choices. You may discuss the findings, the explaination, and possible solutions in a short paragraph followed by your results (30%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53h6r6b3tLLi"
      },
      "outputs": [],
      "source": [
        "## ----- write your code here."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
