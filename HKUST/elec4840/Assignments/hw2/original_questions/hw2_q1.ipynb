{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download and unzip data"
      ],
      "metadata": {
        "id": "Hci3KvN7ivcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_Data.zip\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_Data.zip\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Training_GroundTruth.csv\n",
        "!wget https://isic-challenge-data.s3.amazonaws.com/2016/ISBI2016_ISIC_Part3_Test_GroundTruth.csv\n",
        "!unzip \"./ISBI2016_ISIC_Part3_Test_Data.zip\"\n",
        "!unzip \"./ISBI2016_ISIC_Part3_Training_Data.zip\""
      ],
      "metadata": {
        "id": "ZXeyyLwuD6mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Make training, validation and test image folders by training and test csv files\n",
        "[ImageFolder](https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)"
      ],
      "metadata": {
        "id": "RovDpxZFi-KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "You are recommended to use torchvision.datasets.ImageFolder to load data into the Pytorch dataset.\n",
        "To employ ImageFolder, the images should be arranged into:\n",
        "\n",
        "  root: train/val/test\n",
        "    class_a\n",
        "      a1.png\n",
        "      a2.png\n",
        "      ...\n",
        "    class_b\n",
        "      b1.png\n",
        "      b2.png\n",
        "      ...\n",
        "\n",
        "Write your codes here to organize the original data and split the data into training/validation/test set.\n",
        "'''"
      ],
      "metadata": {
        "id": "2WLrB9eWG3Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Prepare data and build dataloaders"
      ],
      "metadata": {
        "id": "B77B7mO0jw6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "root_train, root_val, root_test = # -- write your codes here: the root path of training/validation/test set\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    # -- write your codes here: data preprocessing and augmentation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    # -- write your codes here: data preprocessing\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def get_train_test_set(batch_size):\n",
        "    train_dataset = ImageFolder(root_train, transform=train_transform)\n",
        "    loader_train = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True\n",
        "        )\n",
        "\n",
        "    val_dataset = ImageFolder(root_val, transform=test_transform)\n",
        "    loader_val = torch.utils.data.DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "        )\n",
        "\n",
        "    test_dataset = ImageFolder(root_test, transform=test_transform)\n",
        "    loader_test = torch.utils.data.DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False\n",
        "        )\n",
        "\n",
        "    return loader_train, loader_val, loader_test\n",
        "\n",
        "batch_size = 16\n",
        "loader_train, loader_val, loader_test = get_train_test_set(batch_size)"
      ],
      "metadata": {
        "id": "vizcUhavjvm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Build the network"
      ],
      "metadata": {
        "id": "zrEdDAUPmJtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement ResNet50"
      ],
      "metadata": {
        "id": "_imLoR2bVbtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import resnet50\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    '''\n",
        "    The single block in ResNet\n",
        "    '''\n",
        "    expansion = 4\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        # -- write your codes here\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -- write your codes here\n",
        "        pass\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, use_fc=False, dropout=None):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        ### stacking layers\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "\n",
        "        self.use_fc = use_fc\n",
        "        self.use_dropout = True if dropout else False\n",
        "        if self.use_fc:\n",
        "            print('Using fc.')\n",
        "            self.fc_add = nn.Linear(512*block.expansion, 512)\n",
        "        if self.use_dropout:\n",
        "            print('Using dropout.')\n",
        "            self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        '''\n",
        "        Buiding ResNet layer by stacking blocks\n",
        "        '''\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, *args):\n",
        "        # -- write your codes here\n",
        "        pass\n",
        "\n",
        "def get_resnet50(pre_trained=True):\n",
        "    Resnet50 = ResNet(Bottleneck, [3, 4, 6, 3], dropout=None)\n",
        "    if pre_trained:\n",
        "        pre_trained = resnet50(weights = \"IMAGENET1K_V2\").state_dict()\n",
        "        new_weights = {k: pre_trained[k] for k in Resnet50.state_dict()}\n",
        "        Resnet50.load_state_dict(new_weights)\n",
        "    return Resnet50"
      ],
      "metadata": {
        "id": "ggxJrmzPmP8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Classification Model"
      ],
      "metadata": {
        "id": "9wENbOekVlwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationModel(nn.Module):\n",
        "    def __init__(self, encoder, num_classes=1):\n",
        "        super(ClassificationModel, self).__init__()\n",
        "        ### apply a vision encoder (ResNet-50 will be applied here)\n",
        "        self.encoder = encoder\n",
        "        # -- write your codes here: add a classifier to project the visual features\n",
        "\n",
        "    def forward(self, x):\n",
        "        # -- write your codes here:\n",
        "        pass\n",
        "\n",
        "resnet50 = get_resnet50(pre_trained=True)\n",
        "model = ClassificationModel(resnet50, 1)"
      ],
      "metadata": {
        "id": "z2ep693sViiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Train and test your model"
      ],
      "metadata": {
        "id": "5Q4AZq_enGEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "max_epoch = 10\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    model = model.cuda()\n",
        "\n",
        "criterion = # -- write your codes here\n",
        "optimizer = # -- write your codes here\n",
        "\n",
        "for epoch in range(max_epoch):\n",
        "    print(\" -- Epoch {}/{}\".format(epoch + 1, max_epoch))\n",
        "\n",
        "    ### training the model\n",
        "    model.train()\n",
        "    for data in tqdm(loader_train):\n",
        "        # -- write your codes here\n",
        "\n",
        "    ### record the training loss and metrics\n",
        "    # -- write your codes here\n",
        "\n",
        "\n",
        "    ### evaluate on validation set\n",
        "    model.eval()\n",
        "    for data in loader_val:\n",
        "        # -- write your codes here\n",
        "\n",
        "    ### record the validation loss and metrics, save the best checkpoint\n",
        "    # -- write your codes here\n",
        "\n",
        "\n",
        "### evaluate on test set\n",
        "model.eval()\n",
        "for data in loader_test:\n",
        "    # -- write your codes here\n",
        "\n",
        "### compute and print the metrics on test set\n",
        "# -- write your codes here"
      ],
      "metadata": {
        "id": "vfSsJ4AbnEID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### plot your training and test curves"
      ],
      "metadata": {
        "id": "oRiwcbu7oWx-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0f056848cf5d2396a4970b625f23716aa539c2ff5334414c1b5d98d7daae66f6"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}